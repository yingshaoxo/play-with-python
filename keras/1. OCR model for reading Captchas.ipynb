{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "champion-joining",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This example demonstrates a simple OCR model built with the Functional API. Apart from combining CNN and RNN, it also illustrates how you can instantiate a new layer and use it as an \"Endpoint layer\" for implementing CTC loss. \n",
    "\n",
    "https://keras.io/examples/vision/captcha_ocr/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-berlin",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beneficial-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "compressed-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto_everything.disk import Disk\n",
    "from auto_everything.terminal import Terminal\n",
    "disk = Disk()\n",
    "t = Terminal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "corrected-hardwood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yingshaoxo/Keras_Lab/ocr_for_captchas'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder = disk.create_a_new_folder_under_home(\"Keras_Lab/ocr_for_captchas\")\n",
    "root_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-selling",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "Download and uncompress the dataset to `~/Keras_Lab/ocr_for_captchas/captcha_images_v2/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "driving-russia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Now you got 1041 images.\n"
     ]
    }
   ],
   "source": [
    "download_file = os.path.join(root_folder, \"captcha_images_v2.zip\")\n",
    "images_folder = os.path.join(root_folder, \"captcha_images_v2\")\n",
    "\n",
    "if not disk.exists(download_file):\n",
    "    t.run_command(\n",
    "        f\"\"\"\n",
    "    wget https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip -P {root_folder}\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "if not disk.exists(images_folder):\n",
    "    disk.uncompress(download_file, images_folder)\n",
    "    \n",
    "print(f\"> Now you got {len(os.listdir(images_folder))} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-longitude",
   "metadata": {},
   "source": [
    "The dataset contains 1040 captcha files as png images. The label for each sample is a string, the name of the file (minus the file extension). \n",
    "\n",
    "We will map each character in the string to an integer for training the model. Similary, we will need to map the predictions of the model back to strings. For this purpose we will maintain two dictionaries, mapping characters to integers, and integers to characters, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forty-peace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/yingshaoxo/Keras_Lab/ocr_for_captchas/captcha_images_v2/226md.png',\n",
       " '/home/yingshaoxo/Keras_Lab/ocr_for_captchas/captcha_images_v2/22d5n.png']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the images directory\n",
    "data_dir = Path(images_folder)\n",
    "\n",
    "# Get list of all the images\n",
    "images = sorted(list(map(str, list(data_dir.glob(\"*.png\")))))\n",
    "images[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automotive-convertible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['226md', '22d5n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove file extension from filename\n",
    "labels = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in images]\n",
    "labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "future-stamp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'b', 'c', 'd', 'e', 'f'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example, get char from a list of strings\n",
    "set(char for string in [\"abc\", \"def\"] for char in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "potential-hobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'm',\n",
       " 'n',\n",
       " 'p',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get char set from the list of labels\n",
    "characters = set(char for label in labels for char in label)\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "spiritual-recipe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found:  1040\n",
      "Number of labels found:  1040\n",
      "Number of unique characters:  19\n",
      "Characters present:  {'n', 'x', 'e', 'm', 'f', '6', '3', 'b', '8', 'd', 'p', '7', 'c', '4', '2', 'w', 'y', '5', 'g'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images found: \", len(images))\n",
    "print(\"Number of labels found: \", len(labels))\n",
    "print(\"Number of unique characters: \", len(characters))\n",
    "print(\"Characters present: \", characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "tough-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for training and validation\n",
    "batch_size = 16\n",
    "\n",
    "# Desired image dimensions\n",
    "img_width = 200\n",
    "img_height = 50\n",
    "\n",
    "# Factor by which the image is going to be downsampled\n",
    "# by the convolutional blocks. We will be using two\n",
    "# convolution blocks and each block will have\n",
    "# a pooling layer which downsample the features by a factor of 2.\n",
    "# Hence total downsampling factor would be 4.\n",
    "downsample_factor = 4\n",
    "\n",
    "# Maximum length of any captcha in the dataset\n",
    "max_length = max([len(label) for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-tournament",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
